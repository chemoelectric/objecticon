import
   http,
   lang(decode_from_file,Text),
   net(URL),
   xml(HtmlParser),
   ipl.scan(past),
   ipl.options,
   ipl.charset,
   xdg,
   io,
   util(use)

global opts, hc

class HttpRequestHelperImpl(HttpRequestHelper)
   private auth

   public override get_authentication(httpc, dom, realm)
      local t
      if t := \auth then {
         # Only succeed once, otherwise httpclient will loop forever retrying
         auth := &null
         return t
      }
   end

   public override modify_redirect(httpc, hreq, hresp)
   end

   public new()
      local u, p
      \opts["a"] ? {
         u := tab(upto(':')) | syserr("Bad -a option")
         move(1)
         p := tab(0)
         auth := Authentication(u, p)
      }
      return
   end
end

procedure main(args)
   local t, cookies
   opts := options(args, [Opt("a",string_with(':'), "USER:PASS#Specify authorization"),
                          Opt("e",string, "URL#Set referer header"),
                          Opt("agent",string, "Set user agent field"),
                          Opt("A",, "Print URLs of any scheme, rather than http, https and file"),
                          Opt("I",integer_range(1,16), "N#Assume data is encoded in ISO 8859-N"),
                          Opt("i",, "Search for IMG links"),
                          Opt("b",, "Search for IMG and A links"),
                          Opt("tee",string,"FILE#Redirect retrieved page to FILE"),
                          Opt("t",integer_range(1),"TIMEOUT#Timeout (in seconds)"),
                          Opt("r",integer_range(0), "RETRIES#Number of retries"),
                          Opt("k",string, "FILE#Load cookies from file"),
                          Opt("text",,"Do text search for tags rather than search parsed document")],
                          "Usage: lslinks [URL]... [OPTIONS]" || Files.EOL ||
                          "List links in URL(s)")

   hc := HttpClient()
   hc.set_timeout(\opts["t"] * 1000)
   hc.set_retries(\opts["r"])
   hc.set_user_agent(\opts["agent"])
   cookies := \opts["k"] | FilePath(BaseDir.ensure_data_home()).child("oicookies").str() | stop("Couldn't access data dir: ", &why)
   t := decode_from_file(cookies) | table()
   hc.set_cookies(t)

   every do_one(!args)

   hc.close()
end

procedure do_one(a)
   local url, hr, res, src, parser, doc, rs, f, s, i

   a := ucs(a) | stop("Argument not UTF-8")
   url := URL(a).normal() | stop("Invalid url: ", a, ": ", &why)

   if f := Files.url_to_file(url) then
      src := Files.file_to_string(f) | stop("Couldn't read file: ", &why)
   else {
      url.scheme == ("http" | "https") | stop("Unknown url scheme: " || url.scheme)
      src := use {
         rs := RamStream(),
         {
            hr := HttpRequest().
               set_url(url).
               set_output_stream(rs).
               set_helper(HttpRequestHelperImpl())
            hr.set_referer(\opts["e"])
            res := hc.retrieve(hr) | stop("Couldn't get: ", &why)
            rs.str()
         }
      }
      url := res.url
   }

   # Optionally save page source
   if s := \opts["tee"] then
      Files.string_to_file(s, src) | stop("Couldn't dump file to ", s, ": ", &why)

   src := if i := \opts["I"] then
      ISO8859.to_ucs(src, i) | stop("Invalid ISO 8859 number")
   else
      Text.liberal_ucs(src)

   parser := HtmlParser()
   doc := parser.parse(src)
   if \opts["i"] then
      do_search(url, src, doc, u"IMG", u"SRC", "")
   else if \opts["b"] then {
      do_search(url, src, doc, u"IMG", u"SRC", "IMG:")
      do_search(url, src, doc, u"A", u"HREF", "A:")
      do_search(url, src, doc, u"AREA", u"HREF", "A:")
   } else {
      do_search(url, src, doc, u"A", u"HREF", "")
      do_search(url, src, doc, u"AREA", u"HREF", "")
   }
end

procedure print(pfx, s, base)
   local url
   url := URL(s) | base.get_relative(s)
   \opts["A"] | (url.scheme == ("http" | "https" | "file")) | fail

   if FileStream.stdout.is_flowterm_tty() then
      write(pfx, Files.begin_link(url), url.str(), Files.end_link())
   else
      write(pfx, url.str())
end

procedure do_search(url, src, doc, tag, attr, pfx)
   local base, n, s

   base := url
   if n := doc.get_root_element().search_tree(u"BASE") then
      base := URL(n.get_attribute(u"HREF"))

   if \opts["text"] then {
      map(src) ? {
         while tab(past(u"<" || map(tag) || u" ")) do {
            if tab(past(map(attr) || u"=\"")) then {
               if s := tab(upto('\"')) then {
                  s := remove_entities(s)
                  print(pfx, s, base)
               }
            }
         }
      }
   } else {
      every n := doc.get_root_element().search_tree(tag) do {
         if s := n.get_attribute(attr) then
            print(pfx, s, base)
      }
   }
end

procedure parse_entity()
   local i
   ="&"
   i := (if any('#') then {
      move(1)
      if any('x') then {
         move(1)
         integer("16r" || tab(many('0-9a-fA-F')))
      } else
         integer(tab(many(&digits)))
   } else
      member(HtmlParser.ENTITIES, string(tab(many(&ucase ++ &lcase))))) | fail
   =";" | fail
   return i
end

#
# Remove the entity characters from a string.
#
procedure remove_entities(s)
   local res, i, j
   res := ""
   s ? repeat {
      res ||:= tab(upto('&') | 0)
      if pos(0) then
         break
      i := &pos
      res ||:= if j := parse_entity() then {
         uchar(j | 63)
      } else {
         &pos := i
         move(1)
      }
   }
   return res
end
