import
   http(HttpClient, HttpRequest),
   lang(decode_from_file),
   net(URL),
   xml(HtmlParser),
   ipl.scan(past),
   ipl.options,
   xdg,
   io

global opts, hc

procedure main(args)
   local t, cookies
   opts := options(args, [Opt("a",string, "USER:PASS#Specify authorization"),
                          Opt("e",string, "URL#Set referer header"),
                          Opt("agent",string, "Set user agent field"),
                          Opt("i",, "Search for IMG links"),
                          Opt("b",, "Search for IMG and A links"),
                          Opt("tee",string,"FILE#Redirect retrieved page to FILE"),
                          Opt("t",integer,"TIMEOUT#Specify timeout (in seconds) to use"),
                          Opt("r",integer, "RETRIES#Specify number of retries to use"),
                          Opt("k",string, "FILE#Load cookies from file"),
                          Opt("text",,"Do text search for tags rather than parse"),
                          Opt("utf8",,"Retrieved data is in utf8 format")],
                          "Usage: lslinks [URL]... [OPTIONS]\n_
                          List links in URL(s)")

   hc := HttpClient()
   hc.set_timeout(\opts["t"] * 1000)
   hc.set_retries(\opts["r"])
   hc.set_user_agent(\opts["agent"])
   cookies := \opts["k"] | FilePath(BaseDir.ensure_data_home()).child("oicookies").str() | stop("Couldn't access data dir: ", &why)
   t := decode_from_file(cookies) | table()
   hc.set_cookies(t)

   every do_one(!args)

   hc.close()
end

procedure do_one(a)
   local url, hr, u, p, res, src, parser, doc, sb
   
   url := URL(a) | stop("Invalid url:" || a)

   if url.scheme == "file" then {
      src := Files.file_to_string(url.path) | stop("Couldn't read file: ", &why)
   } else {
      sb := RamStream()
      hr := HttpRequest().set_output_stream(sb)
      if \opts["a"] then {
         opts["a"] ? {
            u := tab(upto(':')) | help_stop("Bad -a option")
            move(1)
            p := tab(0)
         }
         hr.set_username(u)
         hr.set_password(p)
      }

      hr.set_referer(\opts["e"])
      hr.set_url(url)
      res := hc.retrieve(hr) | stop("Couldn't get: ", &why)

      src := sb.done()
      url := res.url
   }

   # Optionally save page source
   if \opts["tee"] then
      Files.string_to_file(opts["tee"], src) | stop("Couldn't dump file to ", opts["tee"])

   if \opts["utf8"] then
      src := ucs(src) | stop("Couldn't convert utf8")

   parser := HtmlParser()
   doc := parser.parse(src) | stop("couldnt parse page")
   if \opts["i"] then
      do_search(url, src, doc, "IMG", "SRC", "")
   else if \opts["b"] then {
      do_search(url, src, doc, "IMG", "SRC", "IMG:")
      do_search(url, src, doc, "A", "HREF", "A:")
      do_search(url, src, doc, "AREA", "HREF", "A:")
   } else {
      do_search(url, src, doc, "A", "HREF", "")
      do_search(url, src, doc, "AREA", "HREF", "")
   }
end

procedure print(pfx, url)
   if Files.is_flowterm_tty(FileStream.stdout) then
      write(pfx, Files.begin_link(url), url.str(), Files.end_link())
   else
      write(pfx, url.str())
end

procedure do_search(url, src, doc, tag, attr, pfx)
   local base, n, s

   base := url
   if n := doc.get_root_element().search_tree("BASE") then {
      base := URL(n.get_attribute("HREF"))
   }

   if \opts["utf8"] then {
      tag := ucs(tag)
      attr := ucs(attr)
   }
      
   if \opts["text"] then {
      map(src) ? {
         while tab(past("<" || map(tag) || " ")) do {
            if tab(past(map(attr) || "=\"")) then {
               if s := tab(upto("\"")) then {
                  s := remove_entities(s)
                  if match("file://" | "http://" | "https://", s) then
                     print(pfx, URL(s))
                  else
                     print(pfx, base.get_relative(s))
               }
            }
         }
      }
   } else {
      every n := doc.get_root_element().search_tree(tag) do {
         if s := n.get_attribute(attr) then {
            if match("file://" | "http://" | "https://", map(s)) then
               print(pfx, URL(s))
            else
               print(pfx, base.get_relative(s))
         }
      }
   }
end

procedure parse_entity()
   local i
   =u"&"
   i := (if any('#') then {
      move(1)
      if any('x') then {
         move(1)
         integer("16r" || tab(many('0-9a-fA-F')))
      } else
         integer(tab(many(&digits)))
   } else
   member(HtmlParser.ENTITIES, string(tab(many(&ucase ++ &lcase))))) | fail
   =u";" | fail
   return i
end

#
# Remove the entity characters from a string.
#
procedure remove_entities(s)
   local res, i, j
   res := ""
   s ? repeat {
      res ||:= tab(upto('&') | 0)
      if pos(0) then
         break
      i := &pos
      res ||:= if j := parse_entity() then {
         if \opts["utf8"] then
            uchar(j | 63)
         else
            char(j | 63)
      } else {
         &pos := i
         move(1)
      }
   }
   return res
end
